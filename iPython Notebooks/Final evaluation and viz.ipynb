{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from utils.dataloader import *\n",
    "from utils.auc import *\n",
    "from utils import new_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"/beegfs/jmw784/Capstone/LungTilesSorted/\"\n",
    "num_classes = 3\n",
    "tile_dict_path = '/beegfs/jmw784/Capstone/Lung_FileMappingDict.p'\n",
    "imgSize = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([new_transforms.Resize((imgSize,imgSize)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_data = TissueData(root_dir, 'test', transform = transform, metadata=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tile_probability(tile_path):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns an array of probabilities for each class given a tile\n",
    "\n",
    "    @param tile_path: Filepath to the tile\n",
    "    @return: A ndarray of class probabilities for that tile\n",
    "    \"\"\"\n",
    "\n",
    "    # Some tiles are empty with no path, return nan\n",
    "    if tile_path == '':\n",
    "        return np.full(num_classes, np.nan)\n",
    "\n",
    "    tile_path = root_dir + tile_path\n",
    "\n",
    "    with open(tile_path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "    # Model expects a 4D tensor, unsqueeze first dimension\n",
    "    img = transform(img).unsqueeze(0)\n",
    "\n",
    "    # Turn output into probabilities with softmax\n",
    "    var_img = Variable(img, volatile=True)\n",
    "    output = F.softmax(model(var_img)).data.squeeze(0)\n",
    "\n",
    "    return output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(tile_dict_path, 'rb') as f:\n",
    "    tile_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate(file_list, method):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a list of files, return scores for each class according to the\n",
    "    method and labels for those files.\n",
    "\n",
    "    @param file_list: A list of file paths to do predictions on\n",
    "    @param method: 'average' - returns the average probability score across\n",
    "                               all tiles for that file\n",
    "                   'max' - predicts each tile to be the class of the maximum\n",
    "                           score, and returns the proportion of tiles for\n",
    "                           each class\n",
    "\n",
    "    @return: a ndarray of class probabilities for all files in the list\n",
    "             a ndarray of the labels\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for file in file_list:\n",
    "        tile_paths, label = tile_dict[file]\n",
    "\n",
    "        folder = classes[label]\n",
    "\n",
    "        def add_folder(tile_path):\n",
    "            if tile_path == '':\n",
    "                return ''\n",
    "            else:\n",
    "                return folder + '/' + tile_path\n",
    "\n",
    "        # Add the folder for the class name in front\n",
    "        add_folder_v = np.vectorize(add_folder)\n",
    "        tile_paths = add_folder_v(tile_paths)\n",
    "\n",
    "        # Get the probability array for the file\n",
    "        prob_v = np.vectorize(get_tile_probability, otypes=[np.ndarray])\n",
    "        probabilities = prob_v(tile_paths)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        imgSize = probabilities.shape()\n",
    "        newShape = (imgSize[0], imgSize[1], 3)\n",
    "        probabilities = np.reshape(np.stack(probabilities.flat), newShape)\n",
    "        \"\"\"\n",
    "\n",
    "        if method == 'average':\n",
    "            probabilities = np.stack(probabilities.flat)\n",
    "            prediction = np.nanmean(probabilities, axis = 0)\n",
    "\n",
    "        elif method == 'max':\n",
    "            probabilities = np.stack(probabilities.flat)\n",
    "            probabilities = probabilities[~np.isnan(probabilities).all(axis=1)]\n",
    "            votes = np.nanargmax(probabilities, axis=1)\n",
    "            \n",
    "            out = np.array([sum(votes == i) for i in range(num_classes)])\n",
    "            prediction = out / out.sum()\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Method not valid')\n",
    "\n",
    "        predictions.append(prediction)\n",
    "        true_labels.append(label)\n",
    "\n",
    "    return np.array(predictions), np.array(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, pool, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "\n",
    "        self.pool = pool\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        if self.pool:\n",
    "            x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# Define model\n",
    "class cancer_CNN(nn.Module):\n",
    "    def __init__(self, nc, imgSize, ngpu):\n",
    "        super(cancer_CNN, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.imgSize = imgSize\n",
    "        self.ngpu = ngpu\n",
    "        self.data = 'lung'\n",
    "        self.conv1 = BasicConv2d(nc, 16, False, kernel_size=5, padding=1, stride=2, bias=True)\n",
    "        self.conv2 = BasicConv2d(16, 32, False, kernel_size=3, bias=True)\n",
    "        self.conv3 = BasicConv2d(32, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.conv4 = BasicConv2d(64, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.conv5 = BasicConv2d(64, 128, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.conv6 = BasicConv2d(128, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.linear = nn.Linear(5184, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = cancer_CNN(3, imgSize, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = \"/scratch/jmw784/capstone/Charrrrtreuse/experiments/joy15/epoch_10.pth\"\n",
    "state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions, labels = aggregate(test_data.filenames, method='max')\n",
    "roc_auc = get_auc('experiments/15/images/test_AUC.jpg',\n",
    "                  predictions, labels, classes = range(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slides_x, slides_y = 20, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slide = 'slidenamehere'\n",
    "\n",
    "plt.figure(16, 16)\n",
    "gs = gridspec.GridSpec(slides_x, slides_y, wspace=0, hspace=0)\n",
    "\n",
    "for i in range(slides_x):\n",
    "    for j in range(slides_y):\n",
    "        ax = plt.subplot(gs[i, j])\n",
    "        img = pil_loader(tile_dict[slide][0][i, j])\n",
    "        plt.imshow(img)\n",
    "        ax.grid(visible=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
